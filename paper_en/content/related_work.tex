\section{Related Work}
\label{sec:releated-work}

\subsection{Wavelet Transforms and Wavelet Convolutions}
Wavelet transforms decompose signals into subband representations across multiple scales and orientations through a set of analysis filters, combining frequency interpretability with spatial locality. Unlike FFT, wavelet decompositions preserve local support in the spatial domain, making them more suitable as modular operators embedded in convolutional networks. In vision tasks, wavelets have long been used for multi-scale representation and detail enhancement. Recently, wavelet analysis/synthesis has also been integrated into convolutional structures. For example, WTConv performs multi-level wavelet decomposition of features, applies lightweight convolutions on subbands at each level, and reconstructs features via inverse transforms, offering an explicit frequency-band pathway with low modification cost~\cite{wtconv2024}. Nevertheless, many existing wavelet convolutions remain relatively static in both subband processing and cross-branch fusion, limiting their adaptivity to complex scenes.

\subsection{Frequency-domain Modeling and Dynamic Filtering}
Frequency-domain modeling commonly enhances structure and texture representation by explicitly reweighting or filtering frequency components. Dynamic filtering learns content-adaptive frequency weights, enabling input-dependent filtering responses~\cite{dynamicfilter2023}. Frequency-aware fusion further focuses on low-/high-frequency complementarity across scales, generating low-pass and high-pass kernels to resample features and improve residual enhancement~\cite{freqfusion2024}. These works highlight the importance of frequency adaptivity, but they also reveal practical issues when directly adopting FFT or complex resampling operators in detection and dense prediction pipelines, such as resolution-dependent parameterization and increased engineering complexity.

\subsection{Spatial Gating and Position-conditioned Modulation}
Position-conditioned modulation maps external conditions (e.g., coordinates or semantic cues) to channel-wise or pixel-wise scaling factors, thereby enabling spatially varying responses. CoordGate proposes to generate gating weights for spatially varying convolutions from coordinate encodings, improving spatial adaptivity while keeping the computation efficient~\cite{coordgate2024}. Related conditional modulation approaches include FiLM~\cite{perez2018film} and AdaIN~\cite{huang2017adain}, which more generally demonstrate that learnable feature modulation can effectively enrich model expressiveness.

\subsection{Attention Mechanisms and Feature Fusion}
Attention mechanisms explicitly model channel, spatial, or pixel-wise weights to emphasize informative content. For fusing two-branch or multi-branch features, pixel-wise attention provides a finer-grained selection capability. CGA-style fusion computes channel attention and spatial attention to guide pixel attention, achieving per-pixel soft fusion between two feature streams~\cite{cga2024}. This idea is aligned with our motivation: when the spatial convolution branch and the wavelet reconstruction branch exhibit different reliability across regions, pixel-wise fusion can mitigate the interference caused by naive summation.

In summary, our method introduces dynamic frequency modulation and spatial conditioning into the wavelet analysis/synthesis scaffold, and adopts pixel-wise fusion to strengthen cross-branch complementarity, improving adaptivity while preserving plug-and-play usability.
