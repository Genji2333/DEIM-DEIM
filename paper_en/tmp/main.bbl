% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{carion2020detr}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko, ``End-to-end object detection with transformers,'' in \emph{European Conference on Computer Vision}, 2020, pp. 213--229.

\bibitem{zhu2020deformable}
X.~Zhu, W.~Su, L.~Lu, B.~Li, X.~Wang, and J.~Dai, ``Deformable detr: Deformable transformers for end-to-end object detection,'' in \emph{International Conference on Learning Representations}, 2021.

\bibitem{zhao2024rtdetr}
Y.~Zhao, W.~Lv, S.~Xu, J.~Wei, G.~Wang, Q.~Dang, Y.~Liu, and J.~Chen, ``Detrs beat yolos on real-time object detection,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 16\,965--16\,974.

\bibitem{dynamicfilter2023}
\textbf{[作者占位：DynamicFilter 论文作者]}, ``Fft-based dynamic token mixer for vision,'' \emph{arXiv preprint arXiv:2303.03932}, 2023.

\bibitem{freqfusion2024}
\textbf{[作者占位：FreqFusion 论文作者]}, ``Frequency-aware feature fusion for dense image prediction,'' \emph{arXiv preprint arXiv:2408.12879}, 2024.

\bibitem{wtconv2024}
\textbf{[作者占位：WTConv 论文作者]}, ``Wavelet transform convolution,'' \emph{arXiv preprint arXiv:2407.05848}, 2024.

\bibitem{coordgate2024}
\textbf{[作者占位：CoordGate 论文作者]}, ``Coordgate: Efficiently computing spatially-varying convolutions in convolutional neural networks,'' \emph{arXiv preprint arXiv:2401.04680}, 2024.

\bibitem{fsa2024}
\textbf{[作者占位：FSA 论文作者]}, ``Dual-domain strip attention for image restoration,'' \emph{Neural Networks}, 2024.

\bibitem{cga2024}
\textbf{[作者占位：DEA-Net 论文作者]}, ``Dea-net: Single image dehazing based on detail enhanced convolution and content-guided attention,'' in \emph{\textbf{[会议/期刊占位：例如 TIP/ACM MM/等]}}, 2024.

\bibitem{perez2018film}
E.~Perez, F.~Strub, H.~De~Vries, V.~Dumoulin, and A.~Courville, ``Film: Visual reasoning with a general conditioning layer,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2018.

\bibitem{huang2017adain}
X.~Huang and S.~Belongie, ``Arbitrary style transfer in real-time with adaptive instance normalization,'' in \emph{Proceedings of the IEEE International Conference on Computer Vision}, 2017, pp. 1501--1510.

\end{thebibliography}
